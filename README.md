---

### ğŸ“¢ Image-to-Image Translation with Pix2Pix (cGAN)

ğŸ“Œ **Internship Task - Prodigy InfoTech (Generative AI Intern)**

As part of my Generative AI Internship at **Prodigy InfoTech**, I developed an image-to-image translation system using **Pix2Pix**, a type of **Conditional Generative Adversarial Network (cGAN)**. This task provided deep insights into adversarial learning, computer vision, and image synthesis.

---

### ğŸ› ï¸ Implementation Overview

âœ… **Pix2Pix Architecture (cGAN)**
Built a deep learning pipeline with:

* A **U-Net based Generator** that translates input images (e.g., edge maps or sketches) to photo-realistic outputs
* A **PatchGAN Discriminator** that evaluates 70Ã—70 patches for realism and structure

âœ… **Dataset Handling**

* Used paired datasets from `facades`, `maps` via **TensorFlow Datasets**
* Designed fallback support for **custom datasets** and **synthetic data**

âœ… **Training & Loss**

* Combined **Adversarial Loss** and **L1 Loss** to balance realism and accuracy
* Visual output after every few epochs, showing progression of generator performance

âœ… **Visualization and Testing**

* Side-by-side display: `Input Image | Ground Truth | Generated Image`
* Added loss tracking plots and custom test image evaluation pipeline

---

### ğŸ–¼ï¸ Output Sample

Generated images that translate structural representations into detailed visuals using learned pixel mappings.
![Stable Diffusion Output](https://github.com/Yamini192211153/PRODIGY_GA_04/blob/main/GA_Task_4_output.png)
---

### ğŸ’¡ Features

ğŸ¯ **Conditional Generation**: Learns mappings from input to target images
ğŸ§  **Skip Connections**: U-Net enhances low-level detail retention
ğŸ“Š **Loss Plots**: Adversarial vs. reconstruction loss monitoring
ğŸ–¥ï¸ **CLI Training Interface**: Easy to train, visualize, and extend

---

### ğŸ“Œ Internship Credit

Task-04: Part of the **Generative AI Internship at Prodigy InfoTech**
Model: **Pix2Pix (cGAN)** using TensorFlow
Role: **GenAI Intern**
Date: **July 2025**

---
